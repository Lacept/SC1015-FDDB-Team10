{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07484b5e",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6f65f-4dbe-42cb-8129-440f6b1d00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# target encoding for all categorical variables\n",
    "import category_encoders as ce\n",
    "import xgboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e223b74",
   "metadata": {},
   "source": [
    "# Import Datasets + Merging + Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12836620",
   "metadata": {},
   "source": [
    "Importing First Dataset - Video Game sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgsales=pd.read_csv('vgsales.csv')\n",
    "vgsales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgsales.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26172f62",
   "metadata": {},
   "source": [
    "Checking For Empty Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbbabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgsales.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bea588",
   "metadata": {},
   "source": [
    "Removing Empty Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f955a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows = vgsales[vgsales.isnull().any(axis=1)]\n",
    "\n",
    "# Print rows with missing values\n",
    "print(\"Rows with missing values:\")\n",
    "print(missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe after removing all the rows with empty fields\n",
    "cleaned_vg = vgsales.dropna() \n",
    "cleaned_vg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_vg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01680a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_vg['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4a1b4",
   "metadata": {},
   "source": [
    "Removing Irrelevent Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_vg = cleaned_vg[cleaned_vg['Year'] < 2017]\n",
    "cleaned_vg['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0984e482",
   "metadata": {},
   "source": [
    "Importing Second Dataset - Video Game Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_rate = pd.read_csv('all_games.csv')\n",
    "\n",
    "vg_rate['release_date'] = pd.to_datetime(vg_rate['release_date'])\n",
    "\n",
    "# Extract year and create new column\n",
    "vg_rate['Release_Year'] = vg_rate['release_date'].dt.year\n",
    "\n",
    "vg_rate = vg_rate[vg_rate['Release_Year'] < 2017]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf2a53",
   "metadata": {},
   "source": [
    "Changing the Platforms of vg_rate to Short-forms, to Match the Columns of Both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vg_rate['platform'].unique())\n",
    "print(cleaned_vg['Platform'].unique())\n",
    "\n",
    "word_replacement = {\n",
    "    ' Nintendo 64' : 'N64',\n",
    "    ' PlayStation' : 'PS',\n",
    "    ' PlayStation 3' : 'PS3',\n",
    "    ' Dreamcast' : 'DC',\n",
    "    ' Xbox 360' : 'X360',\n",
    "    ' Wii' : 'Wii',\n",
    "    ' Xbox One' : 'XOne',\n",
    "    ' PlayStation 2' : 'PS2',\n",
    "    ' PlayStation 4' : 'PS4',\n",
    "    ' GameCube' : 'GC',\n",
    "    ' Xbox' : 'XB',\n",
    "    ' PC' : 'PC',\n",
    "    ' Game Boy Advance' : 'GBA',\n",
    "    ' 3DS' : '3DS',\n",
    "    ' DS' : 'DS',\n",
    "    ' Wii U' : 'WiiU',\n",
    "    ' PlayStation Vita' : 'PSV',\n",
    "    ' PSP' : 'PSP'\n",
    "}\n",
    "\n",
    "vg_rate['platform'].replace(word_replacement, inplace=True)\n",
    "\n",
    "vg_rate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c25571",
   "metadata": {},
   "source": [
    "Merging Both Datasets Based on Name, Year and Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa093d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_vg = pd.merge(cleaned_vg, vg_rate, left_on=['Name', 'Year', 'Platform'], right_on=['name', 'Release_Year', 'platform'], how='inner')\n",
    "\n",
    "combined_vg = combined_vg[['Rank', 'Name', 'Platform', 'Year', 'Genre', 'Publisher', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales', 'meta_score', 'user_review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b105ee",
   "metadata": {},
   "source": [
    "Adding Missing Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mainline pokemon games\n",
    "mainline_pokemon = [\n",
    "                    {'Rank': 26, 'Name': 'Pokemon Ruby/Pokemon Sapphire', 'Platform': 'GBA', 'Year': 2002, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 6.06, 'EU_Sales': 3.9, 'JP_Sales': 5.38, 'Other_Sales': 0.5, 'Global_Sales': 15.85, 'meta_score': 82, 'user_review': 8.6},\n",
    "                    {'Rank': 50, 'Name': 'Pokemon FireRed/Pokemon LeafGreen', 'Platform': 'GBA', 'Year': 2004, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 4.34, 'EU_Sales': 2.65, 'JP_Sales': 3.15, 'Other_Sales': 0.35, 'Global_Sales': 10.49, 'meta_score': 81, 'user_review': 8.5},\n",
    "                    {'Rank': 131, 'Name': 'Pokemon Emerald', 'Platform': 'GBA', 'Year': 2004, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 2.57, 'EU_Sales': 1.58, 'JP_Sales': 2.06, 'Other_Sales': 0.21, 'Global_Sales': 6.41, 'meta_score': 76, 'user_review': 8.9},\n",
    "                    {'Rank': 21, 'Name': 'Pokemon Diamond/Pokemon Pearl', 'Platform': 'DS', 'Year': 2006, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 6.42, 'EU_Sales': 4.52, 'JP_Sales': 6.04, 'Other_Sales': 1.37, 'Global_Sales': 18.36, 'meta_score': 85, 'user_review': 8.2},\n",
    "                    {'Rank': 89, 'Name': 'Pokemon Platinum', 'Platform': 'DS', 'Year': 2008, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 2.82, 'EU_Sales': 1.78, 'JP_Sales': 2.69, 'Other_Sales': 0.55, 'Global_Sales': 7.84, 'meta_score': 83, 'user_review': 8.9},\n",
    "                    {'Rank': 46, 'Name': 'Pokemon HeartGold/Pokemon SoulSilver', 'Platform': 'DS', 'Year': 2009, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 4.4, 'EU_Sales': 2.77, 'JP_Sales': 3.96, 'Other_Sales': 0.77, 'Global_Sales': 11.9, 'meta_score': 87, 'user_review': 9.1},\n",
    "                    {'Rank': 27, 'Name': 'Pokemon Black/Pokemon White', 'Platform': 'DS', 'Year': 2010, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 5.57, 'EU_Sales': 3.28, 'JP_Sales': 5.65, 'Other_Sales': 0.82, 'Global_Sales': 15.32, 'meta_score': 87, 'user_review': 7.7},\n",
    "                    {'Rank': 82, 'Name': 'Pokemon Black 2/Pokemon White 2', 'Platform': 'DS', 'Year': 2012, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 2.91, 'EU_Sales': 1.86, 'JP_Sales': 3.14, 'Other_Sales': 0.43, 'Global_Sales': 8.33, 'meta_score': 80, 'user_review': 7.9},\n",
    "                    {'Rank': 33, 'Name': 'Pokemon X/Pokemon Y', 'Platform': '3DS', 'Year': 2013, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 5.17, 'EU_Sales': 4.05, 'JP_Sales': 4.34, 'Other_Sales': 0.79, 'Global_Sales': 14.35, 'meta_score': 87, 'user_review': 7.5},\n",
    "                    {'Rank': 50, 'Name': 'Pokemon Omega Ruby/Pokemon Alpha Sapphire', 'Platform': '3DS', 'Year': 2014, 'Genre': 'Role-Playing', 'Publisher': 'Nintendo', 'NA_Sales': 4.23, 'EU_Sales': 3.37, 'JP_Sales': 3.08, 'Other_Sales': 0.65, 'Global_Sales': 11.33, 'meta_score': 82, 'user_review': 7.5},\n",
    "                    ]\n",
    "\n",
    "mainline_pokemon = pd.DataFrame(mainline_pokemon)\n",
    "\n",
    "combined_vg = pd.concat([combined_vg, mainline_pokemon], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e510a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-mainline pokemon games\n",
    "missing_rows = [{'Rank':605, 'Name':'Pokemon Colosseum', 'Platform':'GC', 'Year':2003, 'Genre':'Role-Playing','Publisher':'Nintendo','NA_Sales':1.21,'EU_Sales':0.57,'JP_Sales':0.7,'Other_Sales':0.07,'Global_Sales':2.54,'meta_score':81,'user_review':8.6},\n",
    "                             {'Rank':826, 'Name':'Pokemon Mystery Dungeon: Blue Rescue Team', 'Platform':'DS', 'Year':2005, 'Genre':'Role-Playing','Publisher':'Nintendo','NA_Sales':1.16,'EU_Sales':0.06, 'JP_Sales':0.83,'Other_Sales':0,'Global_Sales':2.05,'meta_score':62,'user_review':8},\n",
    "                             {'Rank':1816, 'Name':'Pokemon Mystery Dungeon: Red Rescue Team', 'Platform':'GBA', 'Year':2005, 'Genre':'Role-Playing','Publisher':'Nintendo','NA_Sales':0.81,'EU_Sales':0.3,'JP_Sales':0,'Other_Sales':0.02,'Global_Sales':1.13,'meta_score':67,'user_review':8.3},\n",
    "                             {'Rank':548, 'Name':'Pokemon Stadium 2', 'Platform':'N64', 'Year':2000, 'Genre':'Strategy','Publisher':'Nintendo','NA_Sales':1.02,'EU_Sales':0.36,'JP_Sales':1.13,'Other_Sales':0.23,'Global_Sales':2.73,'meta_score':78,'user_review':8.3},\n",
    "                             {'Rank':1684, 'Name':'PokePark Wii: Pikachu\\'s Adventure', 'Platform':'Wii', 'Year':2009, 'Genre':'Adventure','Publisher':'Nintendo','NA_Sales':0.55,'EU_Sales':0.17,'JP_Sales':0.42,'Other_Sales':0.06,'Global_Sales':1.2,'meta_score':62,'user_review':7.5}]\n",
    "\n",
    "missing_rows=pd.DataFrame(missing_rows)\n",
    "combined_vg = pd.concat([combined_vg, missing_rows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ce972",
   "metadata": {},
   "source": [
    "Further Cleaning of Data to Remove Games with \"tbd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'user_review' to string type\n",
    "combined_vg['user_review'] = combined_vg['user_review'].astype(str)\n",
    "\n",
    "# remove rows with tbd in user review\n",
    "combined_vg = combined_vg[~combined_vg['user_review'].str.contains('tbd')]\n",
    "\n",
    "# reconvert 'user_review' back to float type\n",
    "combined_vg['user_review'] = combined_vg['user_review'].astype(float)\n",
    "\n",
    "combined_vg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4271511e",
   "metadata": {},
   "source": [
    "Removing Other_Sales and Global_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Other_Sales and Global_Sales\n",
    "combined_vg.drop(['Other_Sales', \"Global_Sales\"], axis=1, inplace=True)\n",
    "combined_vg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa8ce9",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review = combined_vg['user_review']\n",
    "na_sales = combined_vg['NA_Sales']\n",
    "eu_sales = combined_vg['EU_Sales']\n",
    "jp_sales = combined_vg['JP_Sales']\n",
    "year = combined_vg['Year']\n",
    "\n",
    "sales_vars = ['NA_Sales', 'EU_Sales', 'JP_Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b13e0a",
   "metadata": {},
   "source": [
    "Box Plots of Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea3741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for the boxplots\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Loop through each sales variable\n",
    "for i, var in enumerate(['NA_Sales', 'EU_Sales', 'JP_Sales']):\n",
    "    # Create a boxplot for the current variable\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    sb.boxplot(x=var, data=combined_vg)\n",
    "    plt.title(f'Boxplot of {var}')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Sales')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "combined_vg[['NA_Sales', 'EU_Sales', 'JP_Sales']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e633c",
   "metadata": {},
   "source": [
    "Box Plot of Sales, Focusing on Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc850f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each sales variable\n",
    "for i, var in enumerate(['NA_Sales', 'EU_Sales', 'JP_Sales']):\n",
    "    # Create a boxplot for the current variable\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    sb.boxplot(x=var, data=combined_vg, showfliers=False)  # Exclude outliers from the boxplot\n",
    "    \n",
    "    # Get the median value for the current variable\n",
    "    median_value = combined_vg[var].median()\n",
    "    \n",
    "    # Set custom y-axis limits centered around the median\n",
    "    plt.ylim(median_value - 1.5 * combined_vg[var].std(), median_value + 1.5 * combined_vg[var].std())\n",
    "    \n",
    "    plt.title(f'Boxplot of {var}')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Sales (in millions)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68312401",
   "metadata": {},
   "source": [
    "Pie Chart Showing the Distribution of Regional Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25036f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = combined_vg[['NA_Sales','EU_Sales','JP_Sales']]\n",
    "area = area.melt(var_name='Area',value_name='Total_Sales')\n",
    "area = area.groupby('Area')['Total_Sales'].sum().reset_index()\n",
    "\n",
    "plt.pie(area['Total_Sales'],labels=area['Area'], autopct='%.2f%%')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74d25f",
   "metadata": {},
   "source": [
    "Horizontal Bar Plot of Publishers and Regional Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b572c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(24, 12))\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(sales_vars):\n",
    "    # Group the data by 'Publisher' and calculate the sum of sales for each publisher\n",
    "    publisher_sales = combined_vg.groupby('Publisher')[var].sum().sort_values(ascending=False)\n",
    "    \n",
    "    # Select only the top 10 publishers based on sales\n",
    "    top_20_publishers = publisher_sales.head(20)\n",
    "\n",
    "    # Plot the bar plot for top 10 publisher sales\n",
    "    sb.barplot(x=top_20_publishers.values, y=top_20_publishers.index, ax=axes[i], order=top_20_publishers.index)\n",
    "\n",
    "    # Set labels and title for each subplot\n",
    "    axes[i].set_xlabel('Sales')\n",
    "    axes[i].set_ylabel('Publisher')\n",
    "    axes[i].set_title(f'Top 20 Publishers by Sales for {var}')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2631084",
   "metadata": {},
   "source": [
    "Horizontal Bar Plot of Different Genres and Regional Sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(24, 12))\n",
    "\n",
    "genre_na = combined_vg.groupby('Genre')['NA_Sales'].sum().sort_values(ascending=False)\n",
    "sb.barplot(x=genre_na, y=genre_na.index, ax=ax[0], order=genre_na.index)\n",
    "ax[0].set_title('NA Sales by Genre')\n",
    "ax[0].set_xlabel('NA Sales')\n",
    "ax[0].set_ylabel('Genre')\n",
    "\n",
    "genre_eu = combined_vg.groupby('Genre')['EU_Sales'].sum().sort_values(ascending=False)\n",
    "sb.barplot(x=genre_eu, y=genre_eu.index, ax=ax[1], order=genre_eu.index)\n",
    "ax[1].set_title('EU Sales by Genre')\n",
    "ax[1].set_xlabel('EU Sales')\n",
    "ax[1].set_ylabel('Genre')\n",
    "\n",
    "genre_jp = combined_vg.groupby('Genre')['JP_Sales'].sum().sort_values(ascending=False)\n",
    "sb.barplot(x=genre_jp, y=genre_jp.index, ax=ax[2], order=genre_jp.index)\n",
    "ax[2].set_title('JP Sales by Genre')\n",
    "ax[2].set_xlabel('JP Sales')\n",
    "ax[2].set_ylabel('Genre')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a23af",
   "metadata": {},
   "source": [
    "Horizontal Bar Plot of Different Platforms and Regional Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(24, 12))\n",
    "\n",
    "platform_sales = combined_vg.groupby('Platform')['NA_Sales'].sum().sort_values(ascending=False)\n",
    "sb.barplot(x=platform_sales.values, y=platform_sales.index, ax=axes[0])\n",
    "axes[0].set_xlabel('NA')\n",
    "axes[0].set_ylabel('Platform')\n",
    "axes[0].set_title('NA Sales by Platform')\n",
    "\n",
    "platform_sales = combined_vg.groupby('Platform')['EU_Sales'].sum().sort_values(ascending=False)\n",
    "sb.barplot(x=platform_sales.values, y=platform_sales.index, ax=axes[1])\n",
    "axes[1].set_xlabel('EU')\n",
    "axes[1].set_ylabel('Platform')\n",
    "axes[1].set_title('EU Sales by Platform')\n",
    "\n",
    "platform_sales = combined_vg.groupby('Platform')['JP_Sales'].sum().sort_values(ascending=False)\n",
    "sb.barplot(x=platform_sales.values, y=platform_sales.index, ax=axes[2])\n",
    "axes[2].set_xlabel('JP')\n",
    "axes[2].set_ylabel('Platform')\n",
    "axes[2].set_title('JP Sales by Platform')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318065c",
   "metadata": {},
   "source": [
    "Line plot of Sales Over the Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasale = combined_vg.groupby('Year')['NA_Sales'].sum().reset_index()\n",
    "plt.plot(nasale['Year'], nasale['NA_Sales'], color='orange', label='NA Sales') \n",
    "\n",
    "eusale = combined_vg.groupby('Year')['EU_Sales'].sum().reset_index()\n",
    "plt.plot(eusale['Year'], eusale['EU_Sales'], label='EU Sales')  \n",
    "\n",
    "jpsale = combined_vg.groupby('Year')['JP_Sales'].sum().reset_index()\n",
    "plt.plot(jpsale['Year'], jpsale['JP_Sales'], label='JP Sales')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "# Rotate y-axis labels\n",
    "plt.yticks(rotation=90, ha='right')\n",
    "\n",
    "# Add legends\n",
    "plt.legend()\n",
    "\n",
    "plt.show()  # display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f049cb",
   "metadata": {},
   "source": [
    "Line Plot of Sales Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(24, 12))\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(sales_vars):\n",
    "    # Group the data by 'Year' and calculate the sum of sales for each year\n",
    "    sales_by_year = combined_vg.groupby('Year')[var].sum()\n",
    "\n",
    "    # Calculate the difference in sales between consecutive years\n",
    "    sales_diff = sales_by_year.diff()\n",
    "\n",
    "    # Plot the line plot for the differences in sales between consecutive years\n",
    "    axes[i].plot(sales_diff.index, sales_diff, marker='o', linestyle='-')\n",
    "\n",
    "    # Add labels and title\n",
    "    axes[i].set_xlabel('Year')\n",
    "    axes[i].set_ylabel(f'Difference in {var}')\n",
    "    axes[i].set_title(f'Difference in {var} Over Consecutive Years')\n",
    "\n",
    "    # Set tick locations and labels for the x-axis\n",
    "    axes[i].set_xticks(range(int(sales_diff.index.min()), int(sales_diff.index.max()) + 1))\n",
    "    axes[i].tick_params(axis='x', rotation=90)  # Rotate x-axis labels by 90 degrees\n",
    "\n",
    "    # Show grid\n",
    "    axes[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70fe9a",
   "metadata": {},
   "source": [
    "Scatter Plot of Meta Score and Regional Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(24, 12))\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot scatter plot for each sales variable\n",
    "for i, var in enumerate(sales_vars):\n",
    "    sb.scatterplot(x='meta_score', y=var, data=combined_vg, ax=axes[i])\n",
    "    axes[i].set_xlabel('Meta Score')\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bcee37",
   "metadata": {},
   "source": [
    "Scatter Plot of User Review and Regional Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec03a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(24, 12))\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot scatter plot for each sales variable\n",
    "for i, var in enumerate(sales_vars):\n",
    "    sb.scatterplot(x='user_review', y=var, data=combined_vg, ax=axes[i])\n",
    "    axes[i].set_xlabel('User Review')\n",
    "    axes[i].set_ylabel(var)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c34333",
   "metadata": {},
   "source": [
    "Heat Map of All the Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912eaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out only the numeric columns\n",
    "numeric_columns = combined_vg.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = numeric_columns.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sb.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Numeric Variables')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ede18",
   "metadata": {},
   "source": [
    "# Target Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec40c68",
   "metadata": {},
   "source": [
    "Changing the Datatype of Year to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3aec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year is a categorical variable, but it is numeric in the dataset. Thus, we need to change it to string before we can do target encoding\n",
    "combined_vg['Year'] = combined_vg['Year'].astype(str) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a199c3",
   "metadata": {},
   "source": [
    "Target Encoding based on NA_Sales, EU_Sales and JP_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TargetEncoder\n",
    "encoder = ce.TargetEncoder(cols=['Year', 'Genre', 'Publisher', 'Platform'])\n",
    "\n",
    "# Fit and transform the data\n",
    "na_encoded = encoder.fit_transform(combined_vg.drop(columns='NA_Sales'), combined_vg['NA_Sales'])\n",
    "eu_encoded = encoder.fit_transform(combined_vg.drop(columns='EU_Sales'), combined_vg['EU_Sales'])\n",
    "jp_encoded = encoder.fit_transform(combined_vg.drop(columns='JP_Sales'), combined_vg['JP_Sales'])\n",
    "\n",
    "# Concatenate the encoded features with the original DataFrame\n",
    "vg_na = pd.concat([na_encoded, combined_vg['NA_Sales']], axis=1)\n",
    "vg_eu = pd.concat([eu_encoded, combined_vg['EU_Sales']], axis=1)\n",
    "vg_jp = pd.concat([jp_encoded, combined_vg['JP_Sales']], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150e1de4",
   "metadata": {},
   "source": [
    "Display Encoded Dataset Based on NA Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA Encoded Data\n",
    "vg_na.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d19ce",
   "metadata": {},
   "source": [
    "Display Endcoded Dataset Based on EU Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a3de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EU Encoded Data\n",
    "vg_eu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac2958",
   "metadata": {},
   "source": [
    "Display Endcoded Dataset Based on JP Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JP Encoded Data\n",
    "vg_jp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf13057",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47168cb5",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c39b21",
   "metadata": {},
   "source": [
    "Linear Regresion for NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9238a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "x = pd.DataFrame(vg_na.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) # Predictor\n",
    "y = pd.DataFrame(vg_na['NA_Sales']) # Response\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "print(\"Shape of train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Shape of test set:\", X_test.shape, y_test.shape)\n",
    "# Create a Linear Regression object\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Train the Linear Regression model\n",
    "linreg.fit(X_train,y_train)\n",
    "\n",
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients \\t: a = ', linreg.coef_)\n",
    "\n",
    "# Predict the NA_Sales from Predictors\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'r-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of NA Sales (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of NA Sales (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'r-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of NA Sales (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the NA Sales (Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print()\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print(\"Prediction Accuracy of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8da0a5-d7f5-4f1b-8689-edaffd6bbab1",
   "metadata": {},
   "source": [
    "Predicting NA Sales for specific games using the Linear Regression model derived above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea750cf-28c9-4d78-8b8d-23b6ecb25139",
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_Sales_pred = vg_na[vg_na[\"Name\"].isin([\"Grand Theft Auto: Vice City Stories\", \"Destiny\", \"FIFA 15\"])]\n",
    "NA_Sales_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db3e9ed-0a1b-4ea2-8ece-c15af4145a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"Platform\", \"Year\", \"Genre\", \"Publisher\", \"meta_score\", \"user_review\"] #predictors\n",
    "\n",
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(NA_Sales_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b856c6-ccd9-431c-b9b3-02da9144899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = NA_Sales_pred.index)\n",
    "NA_Sales_acc = pd.concat([NA_Sales_pred[[\"Name\", \"NA_Sales\", 'Platform']], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(NA_Sales_acc[\"NA_Sales\"] - NA_Sales_acc[\"PredTotal\"]) / NA_Sales_acc[\"NA_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = NA_Sales_pred.index)\n",
    "NA_Sales_acc = pd.concat([NA_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "NA_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70987fe7-ad87-46bc-8d52-d0814fdf524a",
   "metadata": {},
   "source": [
    "Not a very good prediction as the errors are quite high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ccad3-6eba-449c-8f42-6608a7cc1659",
   "metadata": {},
   "source": [
    "Linear Regression for EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd85f20-59ac-4170-bc94-9809dfc107c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "x = pd.DataFrame(vg_eu.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_eu['EU_Sales']) #response\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "print(\"Shape of train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Shape of test set:\", X_test.shape, y_test.shape)\n",
    "# Create a Linear Regression object\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Train the Linear Regression model\n",
    "linreg.fit(X_train,y_train)\n",
    "\n",
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients \\t: a = ', linreg.coef_)\n",
    "\n",
    "# Predict the EU_Sales from Predictors\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'r-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of EU Sales (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of EU Sales (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'r-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of EU Sales (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the EU Sales (Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print()\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print(\"Prediction Accuracy of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8357f68",
   "metadata": {},
   "source": [
    "Predicting EU Sales for specific games using the Linear Regression model derived above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b5891-6be8-4a51-bbd8-2bf4fe6a97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EU_Sales_pred = vg_eu[vg_eu[\"Name\"].isin([\"Grand Theft Auto: Vice City Stories\", \"Destiny\", \"FIFA 15\"])]\n",
    "EU_Sales_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9f623-db3f-488a-bd51-a73c2ed86d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"Platform\", \"Year\", \"Genre\", \"Publisher\", \"meta_score\", \"user_review\"] #predictors\n",
    "\n",
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(EU_Sales_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca46775-5428-4ecd-a799-ceb1dd2797ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = EU_Sales_pred.index)\n",
    "EU_Sales_acc = pd.concat([EU_Sales_pred[[\"Name\", \"EU_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(EU_Sales_acc[\"EU_Sales\"] - EU_Sales_acc[\"PredTotal\"]) / EU_Sales_acc[\"EU_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error percentage\"], index = EU_Sales_pred.index)\n",
    "EU_Sales_acc = pd.concat([EU_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "EU_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a13bbf",
   "metadata": {},
   "source": [
    "Linear Regression for JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "x = pd.DataFrame(vg_jp.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_jp['JP_Sales']) #response\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "print(\"Shape of train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Shape of test set:\", X_test.shape, y_test.shape)\n",
    "# Create a Linear Regression object\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Train the Linear Regression model\n",
    "linreg.fit(X_train,y_train)\n",
    "\n",
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients \\t: a = ', linreg.coef_)\n",
    "\n",
    "# Predict the JP_Sales from Predictors\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'r-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of JP Sales (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of JP Sales (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'r-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of JP Sales (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the JP Sales (Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print()\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print(\"Prediction Accuracy of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f62ed9",
   "metadata": {},
   "source": [
    "Predicting JP Sales for specific games using the Linear Regression model derived above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "JP_Sales_pred = vg_jp[vg_jp[\"Name\"].isin([\"Grand Theft Auto: Vice City Stories\", \"Destiny\", \"FIFA 15\"])]\n",
    "JP_Sales_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"Platform\", \"Year\", \"Genre\", \"Publisher\", \"meta_score\", \"user_review\"] #predictors\n",
    "\n",
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(JP_Sales_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebbe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = JP_Sales_pred.index)\n",
    "JP_Sales_acc = pd.concat([JP_Sales_pred[[\"Name\", \"JP_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(JP_Sales_acc[\"JP_Sales\"] - JP_Sales_acc[\"PredTotal\"]) / JP_Sales_acc[\"JP_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error percentage\"], index = JP_Sales_pred.index)\n",
    "JP_Sales_acc = pd.concat([JP_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "JP_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62defe59",
   "metadata": {},
   "source": [
    "# Random Forest \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef1fe39",
   "metadata": {},
   "source": [
    "# Random Forest Regression for NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_na.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_na['NA_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5cf13-7b9d-4502-9239-cfa518ee2b13",
   "metadata": {},
   "source": [
    "## Using Grid Search to find the best parameters for our data\n",
    "Find the best parameters to use for the Random Forest Regression by Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ca626-e06e-45be-be9d-4fa5588a6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuning = RandomForestRegressor(random_state = 20) #define the hyperparameters to search over\n",
    "param_grid = {\n",
    "   'n_estimators': [ 100, 150, 200],\n",
    "   'max_features': ['auto', 'sqrt', 'log2'],\n",
    "   'max_depth' : [3,4,5,6,7]\n",
    "}\n",
    "gs = GridSearchCV(estimator = rf_tuning, param_grid = param_grid, cv = 5)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8be3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fit the model\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 200, max_features = 'sqrt', max_depth = 7, random_state = 18, oob_score=True) #used the parameters found\n",
    "#predict the results of the test set with the model trained on the training set values\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print('Goodness of fit of Model \\tTrain Dataset')\n",
    "print('R^2 Score: ', r2_score(y_train, y_pred_train))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_train, y_pred_train))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_train, y_pred_train)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print('\\nPrediction Accuracy of Model \\tTest Dataset')\n",
    "print('R^2 Score: ', r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_test, y_pred)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "random_forest_out_of_bag = RandomForestRegressor(oob_score = True, random_state = 42)\n",
    "random_forest_out_of_bag.fit(X_train, y_train)\n",
    "print('\\nOut of Bag Score: ', random_forest_out_of_bag.oob_score_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63db67b",
   "metadata": {},
   "source": [
    "Plotting the True Values against the predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e010fbd-2a33-4f1c-b397-7f3b9ee02f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Predictions vs the True values(Train)\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_pred_train, color = \"green\") #can delete this also doesnt really help w our analysis\n",
    "axes[0].plot(y_train, y_train, 'black', linewidth = 3)\n",
    "axes[0].set_xlabel(\"True values (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values (Train)\")\n",
    "\n",
    "# Plot the Predictions vs the True values(Test)\n",
    "axes[1].scatter(y_test, y_pred, color = \"blue\")\n",
    "axes[1].plot(y_test, y_test, 'black', linewidth = 3)\n",
    "axes[1].set_xlabel(\"True values (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa8966-9601-4158-837a-f4b40145ca69",
   "metadata": {},
   "source": [
    "Bag score or OOB score is the type of validation technique that is mainly used in bagging algorithms to validate the bagging algorithm. Here a small part of the validation data is taken from the mainstream of the data and the predictions on the particular validation data are done and compared with the other results.\n",
    "\n",
    "The main advantage that the OOB score offers is that here the validation data is not seen by the bagging algorithm and that is why the results on the OOB score are the true results that indicated the actual performance of the bagging algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4769be-bb9c-4f19-a13b-63ad1a2d39e0",
   "metadata": {},
   "source": [
    "increasing the number of estimators increases the mse and rmse slightly, but the random forest model seems accurate enough\n",
    "dont need this anymore cuz i tuned the model to find the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7adf508",
   "metadata": {},
   "source": [
    "## Prediction of NA Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a789402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(NA_Sales_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = rf.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7660d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = NA_Sales_pred.index)\n",
    "NA_Sales_acc = pd.concat([NA_Sales_pred[[\"Name\", \"NA_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(NA_Sales_acc[\"NA_Sales\"] - NA_Sales_acc[\"PredTotal\"]) / NA_Sales_acc[\"NA_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = NA_Sales_pred.index)\n",
    "NA_Sales_acc = pd.concat([NA_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "NA_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b06230",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32578c-8996-41ea-a526-6b86e8d8f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_na.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_na['NA_Sales']) #response\n",
    "y= np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# create the classifier with n_estimators = 300\n",
    "rf = RandomForestRegressor(n_estimators = 200, max_features = 'sqrt', max_depth = 7, random_state = 18, oob_score=True)\n",
    "\n",
    "# fit the model to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_scores = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d8aa3",
   "metadata": {},
   "source": [
    "meta score is the most important feature while genre is the least significant one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26addb8f",
   "metadata": {},
   "source": [
    "## Remove least significant feature from dataset\n",
    "Since Genre has the least significance, we plan to remove Genre from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a90102",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_na.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank', 'Genre'])) #predictor\n",
    "y = pd.DataFrame(vg_na['NA_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "#fit the model\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 200, max_features = 'sqrt', max_depth = 7, random_state = 18, oob_score=True) #used the parameters found\n",
    "#predict the results of the test set with the model trained on the training set values\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print('Goodness of fit of Model \\tTrain Dataset')\n",
    "print('R^2 Score: ', r2_score(y_train, y_pred_train))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_train, y_pred_train))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_train, y_pred_train)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print('\\nPrediction Accuracy of Model \\tTest Dataset')\n",
    "#print('Model accu#racy score with 10 decision-trees :', accuracy_score(y_test, y_pred))\n",
    "print('R^2 Score: ', r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_test, y_pred)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "random_forest_out_of_bag = RandomForestRegressor(oob_score = True, random_state = 42)\n",
    "random_forest_out_of_bag.fit(X_train, y_train)\n",
    "print('Out of Bag Score: ', random_forest_out_of_bag.oob_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ac890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Predictions vs the True values(Train)\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_pred_train, color = \"green\") #can delete this also doesnt really help w our analysis\n",
    "axes[0].plot(y_train, y_train, 'black', linewidth = 3)\n",
    "axes[0].set_xlabel(\"True values (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values (Train)\")\n",
    "\n",
    "# Plot the Predictions vs the True values(Test)\n",
    "axes[1].scatter(y_test, y_pred, color = \"blue\")\n",
    "axes[1].plot(y_test, y_test, 'black', linewidth = 3)\n",
    "axes[1].set_xlabel(\"True values (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec4c7a",
   "metadata": {},
   "source": [
    "## Prediction after removal of Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update of predictors\n",
    "predictors_2 = [\"Platform\", \"Year\", \"Publisher\", \"meta_score\", \"user_review\"] \n",
    "\n",
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(NA_Sales_pred[predictors_2])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = rf.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = NA_Sales_pred.index)\n",
    "NA_Sales_acc = pd.concat([NA_Sales_pred[[\"Name\", \"NA_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(NA_Sales_acc[\"NA_Sales\"] - NA_Sales_acc[\"PredTotal\"]) / NA_Sales_acc[\"NA_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = NA_Sales_pred.index)\n",
    "NA_Sales_acc = pd.concat([NA_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "NA_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f4890-b8ee-4116-9828-ad3dbc5d3213",
   "metadata": {},
   "source": [
    "# Random Forest Regression for EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ec637",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_eu.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_eu['EU_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e409956c",
   "metadata": {},
   "source": [
    "## Using Grid Search to find the best parameters for our data\n",
    "Find the best parameters to use for the Random Forest Regression by Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d784d2-d516-4b8c-9bd5-26deac2d68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuning = RandomForestRegressor(random_state = 20) #define the hyperparameters to search over\n",
    "param_grid = {\n",
    "   'n_estimators': [ 100, 150, 200],\n",
    "   'max_features': ['auto', 'sqrt', 'log2'],\n",
    "   'max_depth' : [3,4,5,6,7]\n",
    "}\n",
    "gs = GridSearchCV(estimator = rf_tuning, param_grid = param_grid, cv = 5)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b554e-1d63-4ef0-8778-804fcd99f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_eu.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_eu['EU_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "#fit the model\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 200, max_features = 'sqrt', max_depth = 7, random_state = 18, oob_score=True) #used the parameters found\n",
    "#predict the results of the test set with the model trained on the training set values\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print('Goodness of fit of Model \\tTrain Dataset')\n",
    "print('R^2 Score: ', r2_score(y_train, y_pred_train))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_train, y_pred_train))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_train, y_pred_train)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print('\\nPrediction Accuracy of Model \\tTest Dataset')\n",
    "#print('Model accu#racy score with 10 decision-trees :', accuracy_score(y_test, y_pred))\n",
    "print('R^2 Score: ', r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_test, y_pred)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "random_forest_out_of_bag = RandomForestRegressor(oob_score = True, random_state = 42)\n",
    "random_forest_out_of_bag.fit(X_train, y_train)\n",
    "print('\\nOut of Bag Score: ', random_forest_out_of_bag.oob_score_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc830d2",
   "metadata": {},
   "source": [
    "Plotting the True Values against the predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb2f78-597b-4035-a3a1-a4e8d5db997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Predictions vs the True values(Train)\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_pred_train, color = \"green\") #can delete this also doesnt really help w our analysis\n",
    "axes[0].plot(y_train, y_train, 'black', linewidth = 3)\n",
    "axes[0].set_xlabel(\"True values (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values (Train)\")\n",
    "\n",
    "# Plot the Predictions vs the True values(Test)\n",
    "axes[1].scatter(y_test, y_pred, color = \"blue\")\n",
    "axes[1].plot(y_test, y_test, 'black', linewidth = 3)\n",
    "axes[1].set_xlabel(\"True values (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f318cd1",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26242ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_eu.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_eu['EU_Sales']) #response\n",
    "y= np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# create the classifier with n_estimators = 300\n",
    "rf = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "\n",
    "# fit the model to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_scores = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91751c8-e505-41b6-bbef-dfde0764b0eb",
   "metadata": {},
   "source": [
    "### Prediction of EU Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d8ce5-48da-44e7-8437-65d15d0e7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(EU_Sales_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = rf.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc06e3-6363-413f-9320-62e4146440ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = EU_Sales_pred.index)\n",
    "EU_Sales_acc = pd.concat([EU_Sales_pred[[\"Name\", \"EU_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(EU_Sales_acc[\"EU_Sales\"] - EU_Sales_acc[\"PredTotal\"]) / EU_Sales_acc[\"EU_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = EU_Sales_pred.index)\n",
    "EU_Sales_acc = pd.concat([EU_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "EU_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492e56a",
   "metadata": {},
   "source": [
    "## Remove least significant feature from our dataset \n",
    "Remove Genre from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00419424",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_eu.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank', 'Genre'])) #predictor\n",
    "y = pd.DataFrame(vg_eu['EU_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "#fit the model\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 200, max_features = 'sqrt', max_depth = 7, random_state = 18, oob_score=True) #used the parameters found\n",
    "#predict the results of the test set with the model trained on the training set values\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print('Goodness of fit of Model \\tTrain Dataset')\n",
    "print('R^2 Score: ', r2_score(y_train, y_pred_train))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_train, y_pred_train))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_train, y_pred_train)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print('\\nPrediction Accuracy of Model \\tTest Dataset')\n",
    "print('R^2 Score: ', r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_test, y_pred)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "random_forest_out_of_bag = RandomForestRegressor(oob_score = True, random_state = 42)\n",
    "random_forest_out_of_bag.fit(X_train, y_train)\n",
    "print('\\nOut of Bag Score: ', random_forest_out_of_bag.oob_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01056e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Predictions vs the True values(Train)\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_pred_train, color = \"green\") \n",
    "axes[0].plot(y_train, y_train, 'black', linewidth = 3)\n",
    "axes[0].set_xlabel(\"True values (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values (Train)\")\n",
    "\n",
    "# Plot the Predictions vs the True values(Test)\n",
    "axes[1].scatter(y_test, y_pred, color = \"blue\")\n",
    "axes[1].plot(y_test, y_test, 'black', linewidth = 3)\n",
    "axes[1].set_xlabel(\"True values (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a8ef8",
   "metadata": {},
   "source": [
    "## Prediction after removal of Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ea1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update of predictors\n",
    "predictors_2 = [\"Platform\", \"Year\", \"Publisher\", \"meta_score\", \"user_review\"] \n",
    "\n",
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(EU_Sales_pred[predictors_2])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = rf.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = EU_Sales_pred.index)\n",
    "EU_Sales_acc = pd.concat([EU_Sales_pred[[\"Name\", \"EU_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(EU_Sales_acc[\"EU_Sales\"] - EU_Sales_acc[\"PredTotal\"]) / EU_Sales_acc[\"EU_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = EU_Sales_pred.index)\n",
    "EU_Sales_acc = pd.concat([EU_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "EU_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d8a43",
   "metadata": {},
   "source": [
    "# Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33422107",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_jp.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_jp['JP_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d412be",
   "metadata": {},
   "source": [
    "## Using Grid Search to find the best parameters for our data\n",
    "Find the best parameters to use for the Random Forest Regression by Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0147d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuning = RandomForestRegressor(random_state = 20) #define the hyperparameters to search over\n",
    "param_grid = {\n",
    "   'n_estimators': [ 100, 150, 200],\n",
    "   'max_features': ['auto', 'sqrt', 'log2'],\n",
    "   'max_depth' : [3,4,5,6,7]\n",
    "}\n",
    "gs = GridSearchCV(estimator = rf_tuning, param_grid = param_grid, cv = 5)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9cceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, max_features = 'sqrt', max_depth = 6, random_state = 18, oob_score=True) #used the parameters found\n",
    "#predict the results of the test set with the model trained on the training set values\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print('Goodness of fit of Model \\tTrain Dataset')\n",
    "print('R^2 Score: ', r2_score(y_train, y_pred_train))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_train, y_pred_train))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_train, y_pred_train)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print('\\nPrediction Accuracy of Model \\tTest Dataset')\n",
    "#print('Model accu#racy score with 10 decision-trees :', accuracy_score(y_test, y_pred))\n",
    "print('R^2 Score: ', r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_test, y_pred)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "random_forest_out_of_bag = RandomForestRegressor(oob_score = True, random_state = 42)\n",
    "random_forest_out_of_bag.fit(X_train, y_train)\n",
    "print('\\nOut of Bag Score: ', random_forest_out_of_bag.oob_score_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236772d2",
   "metadata": {},
   "source": [
    "Plotting the True Values against the predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf93293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Predictions vs the True values(Train)\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_pred_train, color = \"green\") \n",
    "axes[0].plot(y_train, y_train, 'black', linewidth = 3)\n",
    "axes[0].set_xlabel(\"True values (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values (Train)\")\n",
    "\n",
    "# Plot the Predictions vs the True values(Test)\n",
    "axes[1].scatter(y_test, y_pred, color = \"blue\")\n",
    "axes[1].plot(y_test, y_test, 'black', linewidth = 3)\n",
    "axes[1].set_xlabel(\"True values (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcea66d",
   "metadata": {},
   "source": [
    "## Predicting Sales for JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(JP_Sales_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = rf.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88beb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = JP_Sales_pred.index)\n",
    "JP_Sales_acc = pd.concat([JP_Sales_pred[[\"Name\", \"JP_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(JP_Sales_acc[\"JP_Sales\"] - JP_Sales_acc[\"PredTotal\"]) / JP_Sales_acc[\"JP_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = JP_Sales_pred.index)\n",
    "JP_Sales_acc = pd.concat([JP_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "JP_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83c170",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9231c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_jp.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_jp['JP_Sales']) #response\n",
    "y= np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# create the classifier with n_estimators = 300\n",
    "rf = RandomForestRegressor(n_estimators = 100, max_features = 'sqrt', max_depth = 6, random_state = 18, oob_score=True)\n",
    "\n",
    "# fit the model to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_scores = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef841d",
   "metadata": {},
   "source": [
    "Publisher is the most important feature while Platform is the least important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edb747",
   "metadata": {},
   "source": [
    "### Removing Platform from the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a003ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(vg_jp.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank', 'Platform'])) #predictor\n",
    "y = pd.DataFrame(vg_jp['JP_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "#fit the model\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 100, max_features = 'sqrt', max_depth = 6, random_state = 18, oob_score=True) #used the parameters found\n",
    "#predict the results of the test set with the model trained on the training set values\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print('Goodness of fit of Model \\tTrain Dataset')\n",
    "print('R^2 Score: ', r2_score(y_train, y_pred_train))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_train, y_pred_train))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_train, y_pred_train)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print('\\nPrediction Accuracy of Model \\tTest Dataset')\n",
    "#print('Model accu#racy score with 10 decision-trees :', accuracy_score(y_test, y_pred))\n",
    "print('R^2 Score: ', r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error (MAE): ', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE): ', mean_squared_error(y_test, y_pred)) \n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "random_forest_out_of_bag = RandomForestRegressor(oob_score = True, random_state = 42)\n",
    "random_forest_out_of_bag.fit(X_train, y_train)\n",
    "print('\\nOut of Bag Score: ', random_forest_out_of_bag.oob_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Predictions vs the True values(Train)\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_pred_train, color = \"green\") #can delete this also doesnt really help w our analysis\n",
    "axes[0].plot(y_train, y_train, 'black', linewidth = 3)\n",
    "axes[0].set_xlabel(\"True values (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values (Train)\")\n",
    "\n",
    "# Plot the Predictions vs the True values(Test)\n",
    "axes[1].scatter(y_test, y_pred, color = \"blue\")\n",
    "axes[1].plot(y_test, y_test, 'black', linewidth = 3)\n",
    "axes[1].set_xlabel(\"True values (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e88bf6",
   "metadata": {},
   "source": [
    "## Prediction of JP Sales after removing Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0059530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update of predictors\n",
    "predictors_2 = [\"Year\", \"Genre\", \"Publisher\", \"meta_score\", \"user_review\"] \n",
    "\n",
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(JP_Sales_pred[predictors_2])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = rf.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef79355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = JP_Sales_pred.index)\n",
    "JP_Sales_acc = pd.concat([JP_Sales_pred[[\"Name\", \"JP_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(JP_Sales_acc[\"JP_Sales\"] - JP_Sales_acc[\"PredTotal\"]) / JP_Sales_acc[\"JP_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = JP_Sales_pred.index)\n",
    "JP_Sales_acc = pd.concat([JP_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "JP_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30899d-b37e-48b9-8b73-7de23354817f",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af2642e",
   "metadata": {},
   "source": [
    "# NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdec2f7",
   "metadata": {},
   "source": [
    "Tuning the xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37f24a-de60-43df-9a67-fc116a401f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, random_state = 42)\n",
    "x = pd.DataFrame(vg_na.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_na['NA_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "param_grid = {#\"max_depth\":    [4, 5, 6, 7],\n",
    "              \"n_estimators\": [200,300,400],\n",
    "              \"learning_rate\": [0.02, 0.04, 0.05, 0.07, 0.08]}\n",
    "\n",
    "# try out every combination of the above values\n",
    "search = GridSearchCV(xgb, param_grid, cv=5).fit(X_train, y_train)\n",
    "\n",
    "print(\"The best hyperparameters are \",search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d37f0-8cbd-4314-bffa-8e8651344d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(n_estimators=200, learning_rate=0.02, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7, random_state = 42)\n",
    "\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = xgb.predict(X_train)\n",
    "y_test_pred = xgb.predict(X_test)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'r-', linewidth = 4)\n",
    "axes[0].set_xlabel(\"True values of NA Sales (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values NA Sales (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'r-', linewidth = 4)\n",
    "axes[1].set_xlabel(\"True values of NA Sales (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of NA Sales (Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", xgb.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print()\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print(\"Prediction Accuracy of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", xgb.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc326021-cecf-4f43-8cdf-19eccff0159c",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490c488-4090-4260-8fe0-f20cec9706d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(NA_Sales_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = xgb.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c458f-2a01-4d10-93e6-e271e38b3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = NA_Sales_pred.index)\n",
    "NA_Sales_acc = pd.concat([NA_Sales_pred[[\"Name\", \"NA_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(NA_Sales_acc[\"NA_Sales\"] - NA_Sales_acc[\"PredTotal\"]) / NA_Sales_acc[\"NA_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = NA_Sales_pred.index)\n",
    "NA_Sales_acc = pd.concat([NA_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "NA_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a12bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cde84ed",
   "metadata": {},
   "source": [
    "## EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, random_state = 42)\n",
    "x = pd.DataFrame(vg_eu.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_eu['EU_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "param_grid = {#\"max_depth\":    [4, 5, 6, 7],\n",
    "              \"n_estimators\": [200,300,400],\n",
    "              \"learning_rate\": [0.02, 0.04, 0.05, 0.07, 0.08]}\n",
    "\n",
    "# try out every combination of the above values\n",
    "search = GridSearchCV(xgb, param_grid, cv=5).fit(X_train, y_train)\n",
    "\n",
    "print(\"The best hyperparameters are \",search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4153d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(n_estimators=200, learning_rate=0.02, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7, random_state = 42)\n",
    "\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = xgb.predict(X_train)\n",
    "y_test_pred = xgb.predict(X_test)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'r-', linewidth = 4)\n",
    "axes[0].set_xlabel(\"True values of EU Sales (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values EU Sales (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'r-', linewidth = 4)\n",
    "axes[1].set_xlabel(\"True values of EU Sales (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of EU Sales (Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", xgb.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print()\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print(\"Prediction Accuracy of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", xgb.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(EU_Sales_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = xgb.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = EU_Sales_pred.index)\n",
    "EU_Sales_acc = pd.concat([EU_Sales_pred[[\"Name\", \"EU_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(EU_Sales_acc[\"EU_Sales\"] - EU_Sales_acc[\"PredTotal\"]) / EU_Sales_acc[\"EU_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = EU_Sales_pred.index)\n",
    "EU_Sales_acc = pd.concat([EU_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "EU_Sales_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d560ee",
   "metadata": {},
   "source": [
    "# JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, random_state = 42)\n",
    "x = pd.DataFrame(vg_jp.drop(columns=['NA_Sales', 'EU_Sales', 'JP_Sales', 'Name', 'Rank'])) #predictor\n",
    "y = pd.DataFrame(vg_jp['JP_Sales']) #response\n",
    "y = np.ravel(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "param_grid = {\"n_estimators\": [200,300,400],\n",
    "              \"learning_rate\": [0.02, 0.04, 0.05, 0.07, 0.08]}\n",
    "\n",
    "# try out every combination of the above values\n",
    "search = GridSearchCV(xgb, param_grid, cv=5).fit(X_train, y_train)\n",
    "\n",
    "print(\"The best hyperparameters are \",search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67bab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(n_estimators=200, learning_rate=0.02, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7, random_state = 42)\n",
    "\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = xgb.predict(X_train)\n",
    "y_test_pred = xgb.predict(X_test)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'r-', linewidth = 4)\n",
    "axes[0].set_xlabel(\"True values of JP Sales (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values JP Sales (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'r-', linewidth = 4)\n",
    "axes[1].set_xlabel(\"True values of JP Sales (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of JP Sales (Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", xgb.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print()\n",
    "\n",
    "# Check the Prediction Accuracy (on Test Data)\n",
    "print(\"Prediction Accuracy of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", xgb.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) \\t:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Predictors for Prediction\n",
    "X_pred = pd.DataFrame(JP_Sales_pred[predictors])\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_pred = xgb.predict(X_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the Actuals, Predictions and Errors\n",
    "y_pred = pd.DataFrame(y_pred, columns = [\"PredTotal\"], index = JP_Sales_pred.index)\n",
    "JP_Sales_acc = pd.concat([JP_Sales_pred[[\"Name\", \"JP_Sales\"]], y_pred], axis = 1)\n",
    "\n",
    "y_errs = 100 * abs(JP_Sales_acc[\"JP_Sales\"] - JP_Sales_acc[\"PredTotal\"]) / JP_Sales_acc[\"JP_Sales\"]\n",
    "y_errs = pd.DataFrame(y_errs, columns = [\"Error Percentage\"], index = JP_Sales_pred.index)\n",
    "JP_Sales_acc = pd.concat([JP_Sales_acc, y_errs], axis = 1)\n",
    "\n",
    "JP_Sales_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
